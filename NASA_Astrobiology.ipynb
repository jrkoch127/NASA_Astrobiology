{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da76fc1b-d4b4-4e95-b441-eb525db0cfe4",
   "metadata": {},
   "source": [
    "## NASA Astrobiology - SciX/ADS Curation Notebook\n",
    "Updated 02/2025.\n",
    "\n",
    "This notebook consists of Python script that can be run in sections alongside manual maintenance of monthly publications metadata. The goal is to utilize the master spreadsheet (\"NASA_Astrobiology.xlsx\") to keep track of new publications, and to help curate them for ingest to the SciX/ADS repositories. The 'bibcode' column helps to indicate what exists already, and what has yet to be included. If an ADS bibcode is matched, we can add it to the matching row, which will be sent to the ADS Library ([NASA Astrobiology Library](https://scixplorer.org/public-libraries/UTViEyO9T7izQP7i_r6yqA)). Anything not matched, and published in a journal (not in preprint/press/early view), can then be curated and submitted to ADS for indexing.\n",
    "\n",
    "<b>1. Data maintenance:\n",
    "\n",
    "* Manually insert new publications to the spreadsheet with as much metadata as possible.\n",
    "  \n",
    "<b>2. Bibcode Matching:\n",
    "\n",
    "* Run the 'Reference resolver' script, which queries the ADS API (Reference Resolver service) with publication metadata to see if any publications already exist.\n",
    "   \n",
    "* After reviewing the reference resolver results (\"scix_refs_resolved.xlsx\"), insert any bibcode matches into the 'bibcode' column of the master spreadsheet (Note: anything with a score of 1.0 should be an exact match).\n",
    "   \n",
    "<b>3. Updating the Scix/ADS Library:\n",
    "  \n",
    "* Next run the code that adds the bibcodes from the 'bibcodes' column to the ADS Library.\n",
    "   \n",
    "<b>4. Data Curation:\n",
    "\n",
    "* Finally, curate any unmatched/new records to submit to ADS, either by:\n",
    "    * Submitting directly to ADS using the [online submission form](https://ui.adsabs.harvard.edu/feedback/correctabstract)\n",
    "    * Send a text file of the records in [ADS Tagged Format](https://ui.adsabs.harvard.edu/help/data_faq/tagged-format). If there are a large number of records, run the Curation code section of this notebook which will take the metadata from the spreadsheet and generate all the records automatically using the ADS Pyingest Manual Parser service. Email the file formatted '{date}_records.tag' to the SciX/ADS Curation team (Jenny Koch).\n",
    "\n",
    "Please email any questions to Jenny Koch (SciX/ADS Librarian) at jennifer.koch@cfa.harvard.edu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf5e59-4970-4af7-9ce7-2a0eee9d971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from pyingest.serializers.classic import Tagged\n",
    "import datetime\n",
    "\n",
    "# Set up your path to your local directory and the file where your project data is saved\n",
    "filepath = \"\" # Insert a local filepath if necessary\n",
    "filename = \"NASA_Astrobiology.xlsx\"\n",
    "api_token = \"my_api_token\" # Insert your API token here\n",
    "\n",
    "# Get today's date in the desired format\n",
    "todays_date = datetime.datetime.now().strftime(\"%y%m%d\")\n",
    "\n",
    "# Name the .tag file with today's date\n",
    "tagged_output = f\"{todays_date}_records.tag\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3682687-9d00-4c78-95c7-1413822fe3f8",
   "metadata": {},
   "source": [
    "## 2. Bibcode matching\n",
    "Use this section to find new bibcodes for records where one is not yet associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5ef67-a62d-42fa-b282-65df0c578005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the spreadsheet into a Data Frame\n",
    "input_data = pd.read_excel(filepath + filename)\n",
    "data = pd.DataFrame(input_data)\n",
    "\n",
    "# Initialize an empty list for reference strings\n",
    "ref_list = []\n",
    "\n",
    "# Iterate through rows with no bibcode\n",
    "for index, row in data.iterrows():\n",
    "    authors = row[\"authors\"] if pd.notna(row[\"authors\"]) else \"\"\n",
    "    title = row[\"title\"] if pd.notna(row[\"title\"]) else \"\"\n",
    "    doi = str(row[\"doi\"]) if pd.notna(row[\"doi\"]) else \"\"\n",
    "    date = row[\"date\"] if pd.notna(row[\"date\"]) else \"\"\n",
    "    if pd.notna(date) or date != \"\":\n",
    "        year = date[:4]\n",
    "    \n",
    "    # If 'bibcode' is labeled 'preprint', create a reference string from the metadata\n",
    "    if row[\"bibcode\"] == \"preprint\" or pd.isna(row[\"bibcode\"]):\n",
    "        if all(item != \"\" for item in [authors, title, date, doi]) and pd.notna(doi):\n",
    "            ref = {\n",
    "                \"refstr\": f\"{authors}, {title}, {str(year)}, {doi}\",\n",
    "                \"authors\": authors,\n",
    "                \"title\": title,\n",
    "                \"year\": str(year),\n",
    "                \"doi\": doi\n",
    "            }\n",
    "        elif all(item != \"\" for item in [title, date, doi]) and pd.notna(doi):\n",
    "            ref = {\n",
    "                \"refstr\": f\"{title}, {str(year)}, {doi}\",\n",
    "                \"title\": title,\n",
    "                \"year\": str(year),\n",
    "                \"doi\": doi\n",
    "            }\n",
    "        elif doi is not None and pd.notna(doi):\n",
    "            ref = {\n",
    "                \"refstr\": f\"{doi}\",\n",
    "                \"doi\": doi\n",
    "            }\n",
    "        ref_string = json.dumps(ref, ensure_ascii=False)\n",
    "        ref_list.append(ref_string)\n",
    "\n",
    "# Reference Service API request, querying my 'references' list\n",
    "# ADS Prod API Token\n",
    "domain = 'https://api.adsabs.harvard.edu/v1/'\n",
    "def resolve(references):\n",
    "    payload = {'parsed_reference': references}\n",
    "    response = requests.post(\n",
    "        url = domain + 'reference/xml',\n",
    "        headers = {'Authorization': 'Bearer ' + api_token,\n",
    "                 'Content-Type': 'application/json',\n",
    "                 'Accept':'application/json'},\n",
    "        data = json.dumps(payload))\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content)['resolved'], 200\n",
    "    else:\n",
    "        print('From reference status_code is', response.status_code)\n",
    "        return None, response.status_code\n",
    "\n",
    "# Resolve my references, results in 'total results' list\n",
    "references = [json.loads(ref) for ref in ref_list]\n",
    "total_results = []\n",
    "print('Querying %d references with the Reference Service ...'%len(references))\n",
    "for i in range(0, len(references), 16):\n",
    "    results, status = resolve(references[i:i+16])\n",
    "    if results:\n",
    "        total_results += results\n",
    "\n",
    "# Save the results to excel\n",
    "dt = pd.DataFrame(total_results)\n",
    "refs_outfile = \"scix_refs_resolved.xlsx\"\n",
    "dt.to_excel(refs_outfile, index=False)\n",
    "print(f\"Saved results to {refs_outfile}\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910a8a5-0bf3-4356-9aa7-a40a0e5e682a",
   "metadata": {},
   "source": [
    "## 3. Update the Scix/ADS Library\n",
    "Use this section to send bibcodes from the 'bibcode' column to the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce70e4d-4224-4fef-b624-bbacf6dafedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the spreadsheet into a Data Frame\n",
    "input_data = pd.read_excel(filepath + filename)\n",
    "data = pd.DataFrame(input_data)\n",
    "\n",
    "# -- Update/Add Bibcodes to Library\n",
    "biblib = \"UTViEyO9T7izQP7i_r6yqA\" # NASA Astrobiology\n",
    "\n",
    "# Get bibcodes where bibcodes is not null\n",
    "filtered_df = input_data.dropna(subset=['bibcode']) # drop null values\n",
    "\n",
    "# Define conditions to exclude\n",
    "conditions = ['â€¦................','...................','preprint']\n",
    "\n",
    "# Filter out unwanted values\n",
    "filtered_df = filtered_df[~filtered_df['bibcode'].isin(conditions)]\n",
    "\n",
    "# Extract the 'bibcode' column as a list\n",
    "biblist = filtered_df['bibcode'].tolist()\n",
    "      \n",
    "# My ADS API token, and the base url for the ADS Libraries API\n",
    "url = \"https://api.adsabs.harvard.edu/v1/biblib/documents/\" + biblib\n",
    "data = { \n",
    "    \"bibcode\": biblist,\n",
    "    \"action\": \"add\"\n",
    "        }\n",
    "headers = {'Authorization': 'Bearer ' + api_token}\n",
    "    \n",
    "# Send the API request\n",
    "response = requests.post(url=url, data=json.dumps(data), headers=headers)\n",
    "if response.status_code == 200:\n",
    "    print(f'Success: Added {len(set(biblist))} bibcodes to Library')\n",
    "else:\n",
    "    print(f'From SciX/ADS status_code is {response.status_code}. No bibcodes were added to the library at this time.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a047c-c11b-4bd0-97ba-4562276d8f1e",
   "metadata": {},
   "source": [
    "## 4. Data Curation (Pyingest / ADS Tagged formatter)\n",
    "Use this section to generate a .tag file of records from the spreadsheet (where 'bibcode' is empty/null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4e62d-6844-4135-976f-3934067c3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the spreadsheet into a Data Frame\n",
    "input_data = pd.read_excel(filepath + filename)\n",
    "data = pd.DataFrame(input_data)\n",
    "\n",
    "# Initialize list for curated records\n",
    "ingest_records = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "\n",
    "    # Extract the metadata from columns\n",
    "    bibcode = row[\"bibcode\"] if pd.notna(row[\"bibcode\"]) else \"\"\n",
    "    authors = row[\"authors\"] if pd.notna(row[\"authors\"]) else \"\"\n",
    "    affs = row[\"affiliations\"] if pd.notna(row[\"affiliations\"]) else \"\"\n",
    "    title = row[\"title\"] if pd.notna(row[\"title\"]) else \"\"\n",
    "    pubdate = row[\"date\"] if pd.notna(row[\"date\"]) else \"\"\n",
    "    journal = row[\"journal\"] if pd.notna(row[\"journal\"]) else \"\"\n",
    "    vol = row[\"volume\"] if pd.notna(row[\"volume\"]) else \"\"\n",
    "    issue = row[\"issue\"] if pd.notna(row[\"issue\"]) else \"\"\n",
    "    pages = row[\"pages\"] if pd.notna(row[\"pages\"]) else \"\"\n",
    "    abstract = row[\"abstract\"] if pd.notna(row[\"abstract\"]) else \"\"\n",
    "    doi = row[\"doi\"] if pd.notna(row[\"doi\"]) else \"\"\n",
    "\n",
    "    if bibcode == \"\":\n",
    "\n",
    "        # Only process affiliations if they are not missing\n",
    "        if pd.notna(affs) and affs.strip() != '':\n",
    "            if \"AA(\" in affs:\n",
    "                affiliations = affs.replace(\"; \", \"_sepchar_ \").replace(\"<ORCID>\", \"<ID system=\\\"ORCID\\\">\").replace(\"</ORCID>\", \"</ID>\")\n",
    "            else:\n",
    "                affiliations = affs\n",
    "        else:\n",
    "            affiliations = ''  # Leave empty if no affiliations are present\n",
    "        \n",
    "        # Format pages\n",
    "        if pages and \"\\-\" in str(pages):\n",
    "            p = \"pp. \" + str(pages)\n",
    "        elif pages and \"\\-\" not in str(pages):\n",
    "            p = \"page \" + str(pages)\n",
    "\n",
    "        # Format the publication field with journal, volume, issue, and pages\n",
    "        pub = \"\"\n",
    "        if journal and vol and issue and pages:\n",
    "            pub = f\"{journal}, Volume {str(vol)}, Issue {str(issue)}, {str(p)}\"\n",
    "        elif journal and vol and pages:\n",
    "            pub = f\"{journal}, Volume {str(vol)}, {str(p)}\"\n",
    "        elif journal:\n",
    "            pub = f\"{journal}\"\n",
    "\n",
    "        properties = \"\"\n",
    "        if doi:\n",
    "            properties = f\"DOI: {str(doi)}\"\n",
    "            \n",
    "        r = {\n",
    "            \"bibcode\": \"\",\n",
    "            \"authors\": authors.split(\"; \"),\n",
    "            \"affiliations\": affiliations.split(\": \"),\n",
    "            \"pubdate\": pubdate,\n",
    "            \"title\": title,\n",
    "            \"publication\": pub.replace(\".0\",\"\"),\n",
    "            \"abstract\": abstract,\n",
    "            \"properties\": properties\n",
    "        }\n",
    "        ingest_records.append(r)\n",
    "\n",
    "# Pyingest Serializer - Transform records into tagged format\n",
    "outputfp = open(filepath + tagged_output, 'a')\n",
    "try:\n",
    "    for record in ingest_records:\n",
    "        try:\n",
    "            serializer = Tagged()\n",
    "            serializer.write(record, outputfp)\n",
    "        except Exception as e:\n",
    "            print(f\"Serializer failed for record: {record}, Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    outputfp.close()\n",
    "print(f\"Saved {len(ingest_records)} records to {tagged_output}\")\n",
    "\n",
    "# Read the contents of the .tag file\n",
    "with open(filepath + tagged_output, 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Define the pattern to match %F AA(A[A-Z]( and remove the initial AA(\n",
    "pattern1 = r'(%F )AA\\(A([A-Z]\\()'\n",
    "pattern2 = r'\\)\\)\\n%D '\n",
    "pattern3 = r'%F AA\\(\\)\\n%D '\n",
    "\n",
    "# Perform the replacements and count occurrences\n",
    "data = re.sub(pattern1, r'\\1A\\2', data)\n",
    "data = re.sub(pattern2, ')\\n%D ', data)\n",
    "data = re.sub(pattern3, '%D ', data)\n",
    "data = re.sub('_sepchar_', ';', data)\n",
    "\n",
    "# Write the modified content back to the file\n",
    "with open(filepath + tagged_output, 'w') as file:\n",
    "    file.write(data)\n",
    "print(\"Tagged file updated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
